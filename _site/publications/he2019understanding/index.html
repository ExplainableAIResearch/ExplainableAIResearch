<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Global Site Tag (gtag.js) - Google Analytics -->
  <!-- TODO - Enable this when we have the Google Analytics page set up -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107339008-1"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments)};
    gtag('js', new Date());
    gtag('config', 'UA-107339008-1');
  </script> -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <!-- TODO - Add more keywords for SEO -->
  <meta name="keywords" content="xai, explainable ai, explainability, interpretablity">

  <title>
    
      Understanding and Visualizing Deep Visual Saliency Models &middot; Explainable AI
    
  </title>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <!-- TODO - Write a better description -->
  <!-- <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="ML4Code" /> -->

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.12.1/css/dataTables.bootstrap5.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.12.1/js/jquery.dataTables.min.js"></script>
</head>


  <body class="theme-base-0f layout">

    <!-- <a href='/contributing.html' class='ribbon'>Contribute!</a> -->
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Explainable AI
        </a>
      </h1>
      <p class="lead">Current research on explainability and interpretability of machine learning algorithms</p>      
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item">
    <p style="font-size: 12px">
      <input type='text' id='searchTarget' placeholder="Search Repository"/> 
      <button class="button-23 draw" onClick="search();"><i class="fa fa-search"></i></button>
    </p>
  </div>
   <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <!-- <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a> -->
   <!-- <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a> -->
  <a class="sidebar-nav-item" href="/resources.html">Resources</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  </nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">This site is a community effort by the <a href="explainableaiworld.slack.com">Explainable AI</a> members. Please join the group and reach out to the administrators if you have any questions.</p>
    <p style="font-size: 12px"><span style="font-size: 12px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>. Idea and base code for the website adapted from <a href="https://ml4code.github.io/">ml4code</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Understanding and Visualizing Deep Visual Saliency Models</h1>
  <h5>Sen He, Hamed R. Tavakoli, Ali Borji, Yang Mi, Nicolas Pugeault.  2019</h5>
  <p>
    
      [<a href="http://arxiv.org/abs/1903.02501v3" target="_blank">ArXiv</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Understanding and Visualizing Deep Visual Saliency Models' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Understanding and Visualizing Deep Visual Saliency Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
  </p>
  <p><p>Recently, data-driven deep saliency models have achieved high performance and
have outperformed classical saliency models, as demonstrated by results on
datasets such as the MIT300 and SALICON. Yet, there remains a large gap between
the performance of these models and the inter-human baseline. Some outstanding
questions include what have these models learned, how and where they fail, and
how they can be improved. This article attempts to answer these questions by
analyzing the representations learned by individual neurons located at the
intermediate layers of deep saliency models. To this end, we follow the steps
of existing deep saliency models, that is borrowing a pre-trained model of
object recognition to encode the visual features and learning a decoder to
infer the saliency. We consider two cases when the encoder is used as a fixed
feature extractor and when it is fine-tuned, and compare the inner
representations of the network. To study how the learned representations depend
on the task, we fine-tune the same network using the same image set but for two
different tasks: saliency prediction versus scene classification. Our analyses
reveal that: 1) some visual regions (e.g. head, text, symbol, vehicle) are
already encoded within various layers of the network pre-trained for object
recognition, 2) using modern datasets, we find that fine-tuning pre-trained
models for saliency prediction makes them favor some categories (e.g. head)
over some others (e.g. text), 3) although deep models of saliency outperform
classical models on natural images, the converse is true for synthetic stimuli
(e.g. pop-out search arrays), an evidence of significant difference between
human and data-driven saliency models, and 4) we confirm that, after-fine
tuning, the change in inner-representations is mostly due to the task and not
the domain shift in the data.</p>
</p>

  <!-- TODO: <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/he2019understanding.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script> -->

</div>

    </div>

  </body>
</html>
