<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Global Site Tag (gtag.js) - Google Analytics -->
  <!-- TODO - Enable this when we have the Google Analytics page set up -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107339008-1"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments)};
    gtag('js', new Date());
    gtag('config', 'UA-107339008-1');
  </script> -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <!-- TODO - Add more keywords for SEO -->
  <meta name="keywords" content="xai, explainable ai, explainability, interpretablity">

  <title>
    
      The elephant in the interpretability room: Why use attention as explanation when we have saliency methods? &middot; Explainable AI
    
  </title>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <!-- TODO - Write a better description -->
  <!-- <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="ML4Code" /> -->

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.12.1/css/dataTables.bootstrap5.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.12.1/js/jquery.dataTables.min.js"></script>
</head>


  <body class="theme-base-0f layout">

    <!-- <a href='/contributing.html' class='ribbon'>Contribute!</a> -->
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Explainable AI
        </a>
      </h1>
      <p class="lead">Current research on explainability and interpretability of machine learning algorithms</p>      
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item">
    <p style="font-size: 12px">
      <input type='text' id='searchTarget' placeholder="Search Repository"/> 
      <button class="button-23 draw" onClick="search();"><i class="fa fa-search"></i></button>
    </p>
  </div>
   <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <!-- <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a> -->
   <!-- <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a> -->
  <a class="sidebar-nav-item" href="/resources.html">Resources</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  </nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">This site is a community effort by the <a href="explainableaiworld.slack.com">Explainable AI</a> members. Please join the group and reach out to the administrators if you have any questions.</p>
    <p style="font-size: 12px"><span style="font-size: 12px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>. Idea and base code for the website adapted from <a href="https://ml4code.github.io/">ml4code</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?</h1>
  <h5>Jasmijn Bastings, Katja Filippova. Proceedings of the 2020 EMNLP Workshop BlackboxNLP 2020</h5>
  <p>
    
      [<a href="http://arxiv.org/abs/2010.05607v1" target="_blank">ArXiv</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
  </p>
  <p><p>There is a recent surge of interest in using attention as explanation of
model predictions, with mixed evidence on whether attention can be used as
such. While attention conveniently gives us one weight per input token and is
easily extracted, it is often unclear toward what goal it is used as
explanation. We find that often that goal, whether explicitly stated or not, is
to find out what input tokens are the most relevant to a prediction, and that
the implied user for the explanation is a model developer. For this goal and
user, we argue that input saliency methods are better suited, and that there
are no compelling reasons to use attention, despite the coincidence that it
provides a weight for each input. With this position paper, we hope to shift
some of the recent focus on attention to saliency methods, and for authors to
clearly state the goal and user for their explanations.</p>
</p>

  <!-- TODO: <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/bastings2020elephant.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script> -->

</div>

    </div>

  </body>
</html>
