---
layout: publication
title: "A Review on Explainability in Multimodal Deep Neural Nets"
authors: Gargi Joshi, Rahee Walambe, Ketan Kotecha
conference: in IEEE Access, vol. 9, pp. 59800-59821, 2021
year: 2021
additional_links: 
    - {name: "ArXiv", url: "http://dx.doi.org/10.1109/ACCESS.2021.3070212."}
tags: []
---
Artificial Intelligence techniques powered by deep neural nets have achieved
much success in several application domains, most significantly and notably in
the Computer Vision applications and Natural Language Processing tasks.
Surpassing human-level performance propelled the research in the applications
where different modalities amongst language, vision, sensory, text play an
important role in accurate predictions and identification. Several multimodal
fusion methods employing deep learning models are proposed in the literature.
Despite their outstanding performance, the complex, opaque and black-box nature
of the deep neural nets limits their social acceptance and usability. This has
given rise to the quest for model interpretability and explainability, more so
in the complex tasks involving multimodal AI methods. This paper extensively
reviews the present literature to present a comprehensive survey and commentary
on the explainability in multimodal deep neural nets, especially for the vision
and language tasks. Several topics on multimodal AI and its applications for
generic domains have been covered in this paper, including the significance,
datasets, fundamental building blocks of the methods and techniques,
challenges, applications, and future trends in this domain