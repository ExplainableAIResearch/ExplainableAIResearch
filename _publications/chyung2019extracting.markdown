---
layout: publication
title: "Extracting Interpretable Concept-Based Decision Trees from CNNs"
authors: Conner Chyung, Michael Tsang, Yan Liu
conference: 
year: 2019
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/1906.04664v2"}
tags: []
---
In an attempt to gather a deeper understanding of how convolutional neural
networks (CNNs) reason about human-understandable concepts, we present a method
to infer labeled concept data from hidden layer activations and interpret the
concepts through a shallow decision tree. The decision tree can provide
information about which concepts a model deems important, as well as provide an
understanding of how the concepts interact with each other. Experiments
demonstrate that the extracted decision tree is capable of accurately
representing the original CNN's classifications at low tree depths, thus
encouraging human-in-the-loop understanding of discriminative concepts.