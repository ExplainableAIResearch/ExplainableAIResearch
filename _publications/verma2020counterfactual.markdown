---
layout: publication
title: "Counterfactual Explanations for Machine Learning: A Review"
authors: Sahil Verma, John Dickerson, Keegan Hines
conference: 
year: 2020
additional_links: 
    - {name: "ArXiv", url: "http://arxiv.org/abs/2010.10596v1"}
tags: []
---
Machine learning plays a role in many deployed decision systems, often in
ways that are difficult or impossible to understand by human stakeholders.
Explaining, in a human-understandable way, the relationship between the input
and output of machine learning models is essential to the development of
trustworthy machine-learning-based systems. A burgeoning body of research seeks
to define the goals and methods of explainability in machine learning. In this
paper, we seek to review and categorize research on counterfactual
explanations, a specific class of explanation that provides a link between what
could have happened had input to a model been changed in a particular way.
Modern approaches to counterfactual explainability in machine learning draw
connections to the established legal doctrine in many countries, making them
appealing to fielded systems in high-impact areas such as finance and
healthcare. Thus, we design a rubric with desirable properties of
counterfactual explanation algorithms and comprehensively evaluate all
currently-proposed algorithms against that rubric. Our rubric provides easy
comparison and comprehension of the advantages and disadvantages of different
approaches and serves as an introduction to major research themes in this
field. We also identify gaps and discuss promising research directions in the
space of counterfactual explainability.