---
layout: publication
title: "Going Deeper in Frequency Convolutional Neural Network: A Theoretical Perspective"
authors: Xiaohan Zhu, Zhen Cui, Tong Zhang, Yong Li, Jian Yang
conference: 
year: 2021
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2108.05690v1"}
tags: []
---
Convolutional neural network (CNN) is one of the most widely-used successful
architectures in the era of deep learning. However, the high-computational cost
of CNN still hampers more universal uses to light devices. Fortunately, the
Fourier transform on convolution gives an elegant and promising solution to
dramatically reduce the computation cost. Recently, some studies devote to such
a challenging problem and pursue the complete frequency computation without any
switching between spatial domain and frequent domain. In this work, we revisit
the Fourier transform theory to derive feed-forward and back-propagation
frequency operations of typical network modules such as convolution, activation
and pooling. Due to the calculation limitation of complex numbers on most
computation tools, we especially extend the Fourier transform to the Laplace
transform for CNN, which can run in the real domain with more relaxed
constraints. This work more focus on a theoretical extension and discussion
about frequency CNN, and lay some theoretical ground for real application.