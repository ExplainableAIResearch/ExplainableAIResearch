---
layout: publication
title: "Interpretable Multi-Modal Hate Speech Detection"
authors: Prashanth Vijayaraghavan, Hugo Larochelle, Deb Roy
conference: ICML Workshop on AI for Social Good, 2019
year: 2021
additional_links: 
    - {name: "ArXiv", url: "http://arxiv.org/abs/2103.01616v1"}
tags: []
---
With growing role of social media in shaping public opinions and beliefs
across the world, there has been an increased attention to identify and counter
the problem of hate speech on social media. Hate speech on online spaces has
serious manifestations, including social polarization and hate crimes. While
prior works have proposed automated techniques to detect hate speech online,
these techniques primarily fail to look beyond the textual content. Moreover,
few attempts have been made to focus on the aspects of interpretability of such
models given the social and legal implications of incorrect predictions. In
this work, we propose a deep neural multi-modal model that can: (a) detect hate
speech by effectively capturing the semantics of the text along with
socio-cultural context in which a particular hate expression is made, and (b)
provide interpretable insights into decisions of our model. By performing a
thorough evaluation of different modeling techniques, we demonstrate that our
model is able to outperform the existing state-of-the-art hate speech
classification approaches. Finally, we show the importance of social and
cultural context features towards unearthing clusters associated with different
categories of hate.