---
layout: publication
title: "Evaluation of Saliency-based Explainability Method"
authors: Sam Zabdiel Sunder Samuel, Vidhya Kamakshi, Namrata Lodhi, Narayanan C Krishnan
conference: 
year: 2021
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2106.12773v1"}
tags: []
---
A particular class of Explainable AI (XAI) methods provide saliency maps to
highlight part of the image a Convolutional Neural Network (CNN) model looks at
to classify the image as a way to explain its working. These methods provide an
intuitive way for users to understand predictions made by CNNs. Other than
quantitative computational tests, the vast majority of evidence to highlight
that the methods are valuable is anecdotal. Given that humans would be the
end-users of such methods, we devise three human subject experiments through
which we gauge the effectiveness of these saliency-based explainability
methods.