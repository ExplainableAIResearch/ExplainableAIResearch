---
layout: publication
title: "What You See is What You Classify: Black Box Attributions"
authors: Steven Stalder, NathanaÃ«l Perraudin, Radhakrishna Achanta, Fernando Perez-Cruz, Michele Volpi
conference: 
year: 2022
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2205.11266v1"}
tags: []
---
An important step towards explaining deep image classifiers lies in the
identification of image regions that contribute to individual class scores in
the model's output. However, doing this accurately is a difficult task due to
the black-box nature of such networks. Most existing approaches find such
attributions either using activations and gradients or by repeatedly perturbing
the input. We instead address this challenge by training a second deep network,
the Explainer, to predict attributions for a pre-trained black-box classifier,
the Explanandum. These attributions are in the form of masks that only show the
classifier-relevant parts of an image, masking out the rest. Our approach
produces sharper and more boundary-precise masks when compared to the saliency
maps generated by other methods. Moreover, unlike most existing approaches,
ours is capable of directly generating very distinct class-specific masks.
Finally, the proposed method is very efficient for inference since it only
takes a single forward pass through the Explainer to generate all
class-specific masks. We show that our attributions are superior to established
methods both visually and quantitatively, by evaluating them on the PASCAL
VOC-2007 and Microsoft COCO-2014 datasets.