---
layout: publication
title: "BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations"
authors: Xingyu Zhao, Wei Huang, Xiaowei Huang, Valentin Robu, David Flynn
conference: 
year: 2020
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2012.03058v5"}
tags: []
---
Given the pressing need for assuring algorithmic transparency, Explainable AI
(XAI) has emerged as one of the key areas of AI research. In this paper, we
develop a novel Bayesian extension to the LIME framework, one of the most
widely used approaches in XAI -- which we call BayLIME. Compared to LIME,
BayLIME exploits prior knowledge and Bayesian reasoning to improve both the
consistency in repeated explanations of a single prediction and the robustness
to kernel settings. BayLIME also exhibits better explanation fidelity than the
state-of-the-art (LIME, SHAP and GradCAM) by its ability to integrate prior
knowledge from, e.g., a variety of other XAI techniques, as well as
verification and validation (V&V) methods. We demonstrate the desirable
properties of BayLIME through both theoretical analysis and extensive
experiments.