---
layout: publication
title: "Pitfalls of Explainable ML: An Industry Perspective"
authors: Sahil Verma, Aditya Lahiri, John P. Dickerson, Su-In Lee
conference: 
year: 2021
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2106.07758v1"}
tags: []
---
As machine learning (ML) systems take a more prominent and central role in
contributing to life-impacting decisions, ensuring their trustworthiness and
accountability is of utmost importance. Explanations sit at the core of these
desirable attributes of a ML system. The emerging field is frequently called
``Explainable AI (XAI)'' or ``Explainable ML.'' The goal of explainable ML is
to intuitively explain the predictions of a ML system, while adhering to the
needs to various stakeholders. Many explanation techniques were developed with
contributions from both academia and industry. However, there are several
existing challenges that have not garnered enough interest and serve as
roadblocks to widespread adoption of explainable ML. In this short paper, we
enumerate challenges in explainable ML from an industry perspective. We hope
these challenges will serve as promising future research directions, and would
contribute to democratizing explainable ML.