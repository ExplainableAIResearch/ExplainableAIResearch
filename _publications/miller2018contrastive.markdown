---
layout: publication
title: "Contrastive Explanation: A Structural-Model Approach"
authors: Tim Miller
conference: 
year: 2018
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/1811.03163v2"}
tags: []
---
This paper presents a model of contrastive explanation using structural
casual models. The topic of causal explanation in artificial intelligence has
gathered interest in recent years as researchers and practitioners aim to
increase trust and understanding of intelligent decision-making. While
different sub-fields of artificial intelligence have looked into this problem
with a sub-field-specific view, there are few models that aim to capture
explanation more generally. One general model is based on structural causal
models. It defines an explanation as a fact that, if found to be true, would
constitute an actual cause of a specific event. However, research in philosophy
and social sciences shows that explanations are contrastive: that is, when
people ask for an explanation of an event -- the fact -- they (sometimes
implicitly) are asking for an explanation relative to some contrast case; that
is, "Why P rather than Q?". In this paper, we extend the structural causal
model approach to define two complementary notions of contrastive explanation,
and demonstrate them on two classical problems in artificial intelligence:
classification and planning. We believe that this model can help researchers in
subfields of artificial intelligence to better understand contrastive
explanation.