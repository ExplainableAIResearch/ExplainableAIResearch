---
layout: publication
title: "Explanatory Pluralism in Explainable AI"
authors: Yiheng Yao
conference: 
year: 2021
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2106.13976v1"}
tags: []
---
The increasingly widespread application of AI models motivates increased
demand for explanations from a variety of stakeholders. However, this demand is
ambiguous because there are many types of 'explanation' with different
evaluative criteria. In the spirit of pluralism, I chart a taxonomy of types of
explanation and the associated XAI methods that can address them. When we look
to expose the inner mechanisms of AI models, we develop
Diagnostic-explanations. When we seek to render model output understandable, we
produce Explication-explanations. When we wish to form stable generalizations
of our models, we produce Expectation-explanations. Finally, when we want to
justify the usage of a model, we produce Role-explanations that situate models
within their social context. The motivation for such a pluralistic view stems
from a consideration of causes as manipulable relationships and the different
types of explanations as identifying the relevant points in AI systems we can
intervene upon to affect our desired changes. This paper reduces the ambiguity
in use of the word 'explanation' in the field of XAI, allowing practitioners
and stakeholders a useful template for avoiding equivocation and evaluating XAI
methods and putative explanations.