---
layout: publication
title: "Explainable Deep Learning: A Field Guide for the Uninitiated"
authors: Gabrielle Ras, Ning Xie, Marcel van Gerven, Derek Doran
conference: 
year: 2020
additional_links: 
   - {name: "ArXiv", url: "http://arxiv.org/abs/2004.14545v2"}
tags: []
---
Deep neural networks (DNNs) have become a proven and indispensable machine
learning tool. As a black-box model, it remains difficult to diagnose what
aspects of the model's input drive the decisions of a DNN. In countless
real-world domains, from legislation and law enforcement to healthcare, such
diagnosis is essential to ensure that DNN decisions are driven by aspects
appropriate in the context of its use. The development of methods and studies
enabling the explanation of a DNN's decisions has thus blossomed into an
active, broad area of research. A practitioner wanting to study explainable
deep learning may be intimidated by the plethora of orthogonal directions the
field has taken. This complexity is further exacerbated by competing
definitions of what it means ``to explain'' the actions of a DNN and to
evaluate an approach's ``ability to explain''. This article offers a field
guide to explore the space of explainable deep learning aimed at those
uninitiated in the field. The field guide: i) Introduces three simple
dimensions defining the space of foundational methods that contribute to
explainable deep learning, ii) discusses the evaluations for model
explanations, iii) places explainability in the context of other related deep
learning research areas, and iv) finally elaborates on user-oriented
explanation designing and potential future directions on explainable deep
learning. We hope the guide is used as an easy-to-digest starting point for
those just embarking on research in this field.