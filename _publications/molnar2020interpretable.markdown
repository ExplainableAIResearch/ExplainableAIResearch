---
layout: publication
title: "Interpretable Machine Learning -- A Brief History, State-of-the-Art and Challenges"
authors: Christoph Molnar, Giuseppe Casalicchio, Bernd Bischl
conference: Koprinska I. et al. (eds) ECML PKDD 2020 Workshops. ECML PKDD
  2020. Communications in Computer and Information Science, vol 1323. Springer,
  Cham
year: 2020
additional_links: 
   - {name: "ArXiv", url: "http://dx.doi.org/10.1007/978-3-030-65965-3_28"}
tags: []
---
We present a brief history of the field of interpretable machine learning
(IML), give an overview of state-of-the-art interpretation methods, and discuss
challenges. Research in IML has boomed in recent years. As young as the field
is, it has over 200 years old roots in regression modeling and rule-based
machine learning, starting in the 1960s. Recently, many new IML methods have
been proposed, many of them model-agnostic, but also interpretation techniques
specific to deep learning and tree-based ensembles. IML methods either directly
analyze model components, study sensitivity to input perturbations, or analyze
local or global surrogate approximations of the ML model. The field approaches
a state of readiness and stability, with many methods not only proposed in
research, but also implemented in open-source software. But many important
challenges remain for IML, such as dealing with dependent features, causal
interpretation, and uncertainty estimation, which need to be resolved for its
successful application to scientific problems. A further challenge is a missing
rigorous definition of interpretability, which is accepted by the community. To
address the challenges and advance the field, we urge to recall our roots of
interpretable, data-driven modeling in statistics and (rule-based) ML, but also
to consider other areas such as sensitivity analysis, causal inference, and the
social sciences.