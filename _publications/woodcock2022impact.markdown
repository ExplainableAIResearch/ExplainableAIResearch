---
layout: publication
title: "The Impact of Explanations on Layperson Trust in Artificial Intelligence-Driven Symptom Checker Apps: Experimental Study"
authors: Claire Woodcock, Brent Mittelstadt, Dan Busbridge, Grant Blank
conference: J Med Internet Res 2021;23(11):e29386
year: 2022
additional_links: 
   - {name: "ArXiv", url: "http://dx.doi.org/10.2196/29386"}
tags: []
---
To achieve the promoted benefits of an AI symptom checker, laypeople must
trust and subsequently follow its instructions. In AI, explanations are seen as
a tool to communicate the rationale behind black-box decisions to encourage
trust and adoption. However, the effectiveness of the types of explanations
used in AI-driven symptom checkers has not yet been studied. Social theories
suggest that why-explanations are better at communicating knowledge and
cultivating trust among laypeople. This study ascertains whether explanations
provided by a symptom checker affect explanatory trust among laypeople (N=750)
and whether this trust is impacted by their existing knowledge of disease.
  Results suggest system builders developing explanations for symptom-checking
apps should consider the recipient's knowledge of a disease and tailor
explanations to each user's specific need. Effort should be placed on
generating explanations that are personalized to each user of a symptom checker
to fully discount the diseases that they may be aware of and to close their
information gap.