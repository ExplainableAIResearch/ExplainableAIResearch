---
layout: publication
title: "Measure Utility, Gain Trust: Practical Advice for XAI Researcher"
authors: Brittany Davis, Maria Glenski, William Sealy, Dustin Arendt
conference: 
year: 2020
additional_links: 
    - {name: "ArXiv", url: "http://arxiv.org/abs/2009.12924v1"}
tags: []
---
Research into the explanation of machine learning models, i.e., explainable
AI (XAI), has seen a commensurate exponential growth alongside deep artificial
neural networks throughout the past decade. For historical reasons, explanation
and trust have been intertwined. However, the focus on trust is too narrow, and
has led the research community astray from tried and true empirical methods
that produced more defensible scientific knowledge about people and
explanations. To address this, we contribute a practical path forward for
researchers in the XAI field. We recommend researchers focus on the utility of
machine learning explanations instead of trust. We outline five broad use cases
where explanations are useful and, for each, we describe pseudo-experiments
that rely on objective empirical measurements and falsifiable hypotheses. We
believe that this experimental rigor is necessary to contribute to scientific
knowledge in the field of XAI.