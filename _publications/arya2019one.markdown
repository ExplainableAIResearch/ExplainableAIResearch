---
layout: publication
title: "One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques"
authors: Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Q. Vera Liao, Ronny Luss, Aleksandra MojsiloviÄ‡, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra, John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush R. Varshney, Dennis Wei, Yunfeng Zhang
conference: 
year: 2019
additional_links: 
    - {name: "ArXiv", url: "http://arxiv.org/abs/1909.03012v2"}
tags: []
---
As artificial intelligence and machine learning algorithms make further
inroads into society, calls are increasing from multiple stakeholders for these
algorithms to explain their outputs. At the same time, these stakeholders,
whether they be affected citizens, government regulators, domain experts, or
system developers, present different requirements for explanations. Toward
addressing these needs, we introduce AI Explainability 360
(http://aix360.mybluemix.net/), an open-source software toolkit featuring eight
diverse and state-of-the-art explainability methods and two evaluation metrics.
Equally important, we provide a taxonomy to help entities requiring
explanations to navigate the space of explanation methods, not only those in
the toolkit but also in the broader literature on explainability. For data
scientists and other users of the toolkit, we have implemented an extensible
software architecture that organizes methods according to their place in the AI
modeling pipeline. We also discuss enhancements to bring research innovations
closer to consumers of explanations, ranging from simplified, more accessible
versions of algorithms, to tutorials and an interactive web demo to introduce
AI explainability to different audiences and application domains. Together, our
toolkit and taxonomy can help identify gaps where more explainability methods
are needed and provide a platform to incorporate them as they are developed.