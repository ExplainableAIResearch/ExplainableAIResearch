---
layout: publication
title: "Explainability Pitfalls: Beyond Dark Patterns in Explainable AI"
authors: Upol Ehsan, Mark O. Riedl
conference: 
year: 2021
additional_links: 
    - {name: "ArXiv", url: "http://arxiv.org/abs/2109.12480v1"}
tags: []
---
To make Explainable AI (XAI) systems trustworthy, understanding harmful
effects is just as important as producing well-designed explanations. In this
paper, we address an important yet unarticulated type of negative effect in
XAI. We introduce explainability pitfalls(EPs), unanticipated negative
downstream effects from AI explanations manifesting even when there is no
intention to manipulate users. EPs are different from, yet related to, dark
patterns, which are intentionally deceptive practices. We articulate the
concept of EPs by demarcating it from dark patterns and highlighting the
challenges arising from uncertainties around pitfalls. We situate and
operationalize the concept using a case study that showcases how, despite best
intentions, unsuspecting negative effects such as unwarranted trust in
numerical explanations can emerge. We propose proactive and preventative
strategies to address EPs at three interconnected levels: research, design, and
organizational.